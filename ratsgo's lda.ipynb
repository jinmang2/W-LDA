{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출처: https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/07/09/lda/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [[\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hadoop', 'Big Data', 'HBase', 'Java', 'Spark', 'Storm', 'Cassandra'],\n",
       " ['NoSQL', 'MongoDB', 'Cassandra', 'HBase', 'Postgres'],\n",
       " ['Python', 'scikit-learn', 'scipy', 'numpy', 'statsmodels', 'pandas'],\n",
       " ['R', 'Python', 'statistics', 'regression', 'probability'],\n",
       " ['machine learning', 'regression', 'decision trees', 'libsvm'],\n",
       " ['Python', 'R', 'Java', 'C++', 'Haskell', 'programming languages'],\n",
       " ['statistics', 'probability', 'mathematics', 'theory'],\n",
       " ['machine learning', 'scikit-learn', 'Mahout', 'neural networks'],\n",
       " ['neural networks', 'deep learning', 'Big Data', 'artificial intelligence'],\n",
       " ['Hadoop', 'Java', 'MapReduce', 'Big Data'],\n",
       " ['statistics', 'R', 'statsmodels'],\n",
       " ['C++', 'deep learning', 'artificial intelligence', 'probability'],\n",
       " ['pandas', 'R', 'Python'],\n",
       " ['databases', 'HBase', 'Postgres', 'MySQL', 'MongoDB'],\n",
       " ['libsvm', 'regression', 'support vector machines']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "# topic 수 지정\n",
    "K = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단어를 임의의 토픽에 랜덤 배정\n",
    "document_topics = [[random.randrange(K) for word in document]\n",
    "                   for document in documents]\n",
    "\n",
    "# 각 토픽이 각 문서에 할당되는 횟수\n",
    "# Counter로 구성된 리스트\n",
    "# 각 Counter는 각 문서를 의미\n",
    "document_topic_counts = [Counter() for _ in documents]\n",
    "\n",
    "# 각 단어가 각 토픽에 할당되는 횟수\n",
    "# Counter로 구성된 리스트\n",
    "# 각 Counter는 각 토픽을 의미\n",
    "topic_word_counts = [Counter() for _ in range(K)]\n",
    "\n",
    "# 각 토픽에 할당되는 총 단어의 수\n",
    "# 숫자로 구성된 리스트\n",
    "# 각각의 숫자는 각 토픽을 의미\n",
    "topic_counts = [0 for _ in range(K)]\n",
    "\n",
    "# 각 문서에 포함되는 총 단어의 수\n",
    "# 숫자로 구성된 리스트\n",
    "# 각각의 숫자는 문서를 의미\n",
    "document_lengths = [len(document) for document in documents]\n",
    "\n",
    "# 서로 다른 단어의 수\n",
    "distinct_words = set(word for document in documents for word in document)\n",
    "V = len(distinct_words)\n",
    "\n",
    "# 총 문서의 수\n",
    "D = len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문서별 할당된 topic을 랜덤 초기화 후\n",
    "# AB를 구하는 데 필요한 숫자를 counting\n",
    "for d in range(D):\n",
    "    for word, topic in zip(documents[d], document_topics[d]):\n",
    "        document_topic_counts[d][topic] += 1\n",
    "        topic_word_counts[topic][word] += 1\n",
    "        topic_counts[topic] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_new_topic(d, word):\n",
    "    return sample_from([topic_weight(d, word, k) for k in range(K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_weight(d, word, k):\n",
    "    # 문서와 문서의 단어가 주어지면\n",
    "    # k번째 토픽의 weight를 반환\n",
    "    return p_word_given_topic(word, k) * p_topic_given_document(k, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_word_given_topic(word, topic, beta=0.1):\n",
    "    # topic에 속한 단어 가운데 word의 비율\n",
    "    # (beta를 더해 smoothing)\n",
    "    return ((topic_word_counts[topic][word] + beta) /\n",
    "           (topic_counts[topic] + V * beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_topic_given_document(topic, d, alpha=0.1):\n",
    "    # 문서 d의 모든 단어 가운데 topic에 속하는\n",
    "    # 단어의 비율 (alpha를 더해 smoothing)\n",
    "    return ((document_topic_counts[d][topic] + alpha) /\n",
    "            (document_lengths[d] + K * alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from(weights):\n",
    "    # i를 확률로 반환\n",
    "    total = sum(weights)\n",
    "    # 0과 total 사이를 균일하게 선택\n",
    "    rnd = total * random.random()\n",
    "    # 아래 식을 만족하는 가장 작은 i를 반환\n",
    "    # weights[0] + ... + weights[i] >= rnd\n",
    "    for i, w in enumerate(weights):\n",
    "        rnd -= w\n",
    "        if rnd <= 0:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10000):\n",
    "    for d in range(D):\n",
    "        for i, (word, topic) in enumerate(zip(documents[d],\n",
    "                                              document_topics[d])):\n",
    "            # 깁스 샘플링 수행을 위해\n",
    "            # 샘플링 대상 word와 topic을 제외하고 세어봄\n",
    "            document_topic_counts[d][topic] -= 1\n",
    "            topic_word_counts[topic][word] -= 1\n",
    "            topic_counts[topic] -= 1\n",
    "            document_lengths[d] -= 1\n",
    "            \n",
    "            # 깁스 샘플링 대상 word와 topic을 제외한\n",
    "            # 말뭉치 모든 word의 topic 정보를 토대로\n",
    "            # 샘플링 대상 word의 새로운 topic을 선택\n",
    "            new_topic = choose_new_topic(d, word)\n",
    "            document_topics[d][i] = new_topic\n",
    "            \n",
    "            # 샘플링 대상 word의 새로운 topic을 반영해\n",
    "            # 말뭉치 정보 업데이트\n",
    "            document_topic_counts[d][new_topic] += 1\n",
    "            topic_word_counts[new_topic][word] += 1\n",
    "            topic_counts[new_topic] += 1\n",
    "            document_lengths[d] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({3: 0, 0: 0, 2: 2, 1: 5}),\n",
       " Counter({3: 0, 2: 5, 1: 0, 0: 0}),\n",
       " Counter({1: 0, 0: 1, 2: 1, 3: 4}),\n",
       " Counter({0: 5, 2: 0, 3: 0, 1: 0}),\n",
       " Counter({3: 3, 2: 0, 1: 0, 0: 1}),\n",
       " Counter({3: 0, 2: 0, 0: 3, 1: 3}),\n",
       " Counter({0: 4, 3: 0, 2: 0, 1: 0}),\n",
       " Counter({2: 0, 0: 0, 1: 0, 3: 4}),\n",
       " Counter({1: 3, 3: 1, 0: 0, 2: 0}),\n",
       " Counter({0: 0, 2: 0, 3: 0, 1: 4}),\n",
       " Counter({2: 2, 0: 1, 3: 0, 1: 0}),\n",
       " Counter({2: 0, 1: 2, 3: 0, 0: 2}),\n",
       " Counter({0: 2, 3: 0, 2: 1, 1: 0}),\n",
       " Counter({1: 0, 2: 5, 3: 0, 0: 0}),\n",
       " Counter({0: 0, 2: 0, 3: 3, 1: 0})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'HBase': 0,\n",
       "         'scikit-learn': 0,\n",
       "         'pandas': 0,\n",
       "         'R': 3,\n",
       "         'regression': 1,\n",
       "         'Java': 0,\n",
       "         'C++': 1,\n",
       "         'Haskell': 0,\n",
       "         'statistics': 3,\n",
       "         'artificial intelligence': 0,\n",
       "         'Hadoop': 0,\n",
       "         'Big Data': 0,\n",
       "         'statsmodels': 0,\n",
       "         'libsvm': 0,\n",
       "         'Spark': 0,\n",
       "         'Storm': 0,\n",
       "         'programming languages': 0,\n",
       "         'machine learning': 0,\n",
       "         'MapReduce': 0,\n",
       "         'scipy': 0,\n",
       "         'numpy': 0,\n",
       "         'support vector machines': 0,\n",
       "         'Cassandra': 0,\n",
       "         'deep learning': 1,\n",
       "         'decision trees': 1,\n",
       "         'neural networks': 0,\n",
       "         'databases': 0,\n",
       "         'probability': 3,\n",
       "         'theory': 1,\n",
       "         'NoSQL': 0,\n",
       "         'Mahout': 0,\n",
       "         'mathematics': 1,\n",
       "         'Postgres': 0,\n",
       "         'Python': 4,\n",
       "         'MySQL': 0,\n",
       "         'MongoDB': 0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_counts[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
